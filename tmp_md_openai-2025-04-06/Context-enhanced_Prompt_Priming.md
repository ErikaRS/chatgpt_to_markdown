# Context-enhanced Prompt Priming

Created: 2023-08-21 10:21:05
Last Updated: 2023-08-21 10:21:14

### User - 2023-08-21 10:21:05

What is it called when you send context along with an LLM prompt to help it provide a better answer?

### Assistant - 2023-08-21 10:21:14

When you send context along with a prompt to a language model like OpenAI's GPT-3 or GPT-4, it's typically referred to as "priming" the model. Priming helps the model understand the context or background information so it can produce more relevant and accurate responses. It's a way to guide the model's behavior and set expectations for the kind of output you're seeking.

